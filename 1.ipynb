{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0a8ca59-8bf6-4447-8ccc-147f8bb4b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from typing import Union, Tuple, List\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from skimage import color, feature\n",
    "import tkinter as tk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "5fbee145-c254-447d-a958-b4b89aef8618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from typing import Union, Tuple, List\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "\n",
    "\n",
    "def computeHomography(src_pts_nx2: np.ndarray, dest_pts_nx2: np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Compute the homography matrix.\n",
    "    Arguments:\n",
    "        src_pts_nx2: the coordinates of the source points (nx2 numpy array).\n",
    "        dest_pts_nx2: the coordinates of the destination points (nx2 numpy array).\n",
    "    Returns:\n",
    "        H_3x3: the homography matrix (3x3 numpy array).\n",
    "    '''\n",
    "\n",
    "    # Each equation pair is of the form:\n",
    "    # [ xs(i) ys(i) 1 0 0 0 -xd(i)xs(i) -xd(i)ys(i) -xd(i) ]  * [h11 h12 h13 h21 h22 h23 h31 h32 h33]^T = [0 0]\n",
    "    # [ 0 0 0 xs(i) ys(i) 1 -yd(i)xs(i) -yd(i)ys(i) -yd(i) ]\n",
    "\n",
    "    src_pts_nx2 = np.asarray(src_pts_nx2)\n",
    "    dest_pts_nx2 = np.asarray(dest_pts_nx2)\n",
    "\n",
    "    n = src_pts_nx2.shape[0]\n",
    "    A = np.zeros((2*n, 9))\n",
    "                  \n",
    "    for i in range(n):\n",
    "        \n",
    "        # Create the two equations for each point\n",
    "        xs,ys = src_pts_nx2[i, 0], src_pts_nx2[i, 1]\n",
    "        xd,yd = dest_pts_nx2[i, 0], dest_pts_nx2[i, 1]\n",
    "        eqn1 = np.array([xs, ys, 1, 0, 0, 0, -xd*xs, -xd*ys, -xd])\n",
    "        eqn2 = np.array([0, 0, 0, xs, ys, 1, -yd*xs, -yd*ys, -yd])\n",
    "\n",
    "        # Fill the two equations into A\n",
    "        A[2*i] = eqn1\n",
    "        A[2*i+1] = eqn2\n",
    "\n",
    "    # The eigenvector h associated with lmda_min of A^T*A minimizes L(h)\n",
    "    ev, evec = np.linalg.eig(np.dot(A.T, A))\n",
    "    h = evec[:, np.argmin(ev)]\n",
    "    H = h.reshape(3,3)\n",
    "   \n",
    "    # Visualization for testing purposes\n",
    "    # pil_img1 = Image.fromarray(img1)\n",
    "    # pil_img2 = Image.fromarray(img2)\n",
    "    # draw1 = ImageDraw.Draw(pil_img1)\n",
    "    # draw2 = ImageDraw.Draw(pil_img2)\n",
    "\n",
    "    # for (x, y) in src_pts_nx2:\n",
    "    #     draw1.ellipse((x-5, y-5, x+5, y+5), fill=(255,0,0), outline=(255,0,0), width=2)\n",
    "\n",
    "    # for (x, y) in dest_pts_nx2:\n",
    "    #     draw2.ellipse((x-5, y-5, x+5, y+5), fill=(0,255,0), outline=(0,255,0), width=2)\n",
    "\n",
    "    # Display both images\n",
    "    # pil_img1.show()\n",
    "    # pil_img2.show()\n",
    "\n",
    "\n",
    "    return H\n",
    "    \n",
    "    \n",
    "\n",
    "def applyHomography(H_3x3: np.ndarray, src_pts_nx2: np.ndarray) ->  np.ndarray:\n",
    "    '''\n",
    "    Apply the homography matrix to the source points.\n",
    "    Arguments:\n",
    "        H_3x3: the homography matrix (3x3 numpy array).\n",
    "        src_pts_nx2: the coordinates of the source points (nx2 numpy array).\n",
    "    Returns:\n",
    "        dest_pts_nx2: the coordinates of the destination points (nx2 numpy array).\n",
    "    '''\n",
    "\n",
    "    # Applying the homography is fairly straightforward:\n",
    "    # Convert each point into a homogenous coordinate, apply homography, then dehomogenize the resulting points\n",
    "    n = src_pts_nx2.shape[0]\n",
    "\n",
    "    # Convert to homogenous coordinates by adding a 1 to every point\n",
    "    src_pts_homog = np.hstack((src_pts_nx2, np.ones((n,1))))\n",
    "\n",
    "    # Compute q = H*p\n",
    "    dest_pts_homog = np.dot(H_3x3, src_pts_homog.T) # because src_pts_homog is nx3, need 3xn\n",
    "\n",
    "    # Dehomogenize by dividing by last column and then removing it\n",
    "    dest_pts_nx2 = dest_pts_homog[:2, :]/dest_pts_homog[2, :]\n",
    "\n",
    "    return dest_pts_nx2.T\n",
    "\n",
    "\n",
    "\n",
    "def showCorrespondence(img1: np.ndarray, img2: np.ndarray, pts1_nx2: np.ndarray, pts2_nx2: np.ndarray) -> Image.Image:\n",
    "    '''\n",
    "    Show the correspondences between the two images.\n",
    "    Arguments:\n",
    "        img1: the first image (array).\n",
    "        img2: the second image (array).\n",
    "        pts1_nx2: the coordinates of the points in the first image (nx2 numpy array).\n",
    "        pts2_nx2: the coordinates of the points in the second image (nx2 numpy array).\n",
    "    Returns:\n",
    "        result: image depicting the correspondences.\n",
    "    '''\n",
    "    print(f'Original img1 shape: {img1.shape}')  #TESTCODE\n",
    "    print(f'Original img2 shape: {img2.shape}')  #TESTCODE\n",
    "    \n",
    "    # Handling the case where one image is RGBA and one is just RGB\n",
    "    if img1.shape[2] != img2.shape[2]:\n",
    "        if img1.shape[2] == 4:  # img1 is RGBA, convert to RGB\n",
    "            img1 = img1[:, :, :3]\n",
    "        elif img2.shape[2] == 4:  # img2 is RGBA, convert to RGB\n",
    "            img2 = img2[:, :, :3]\n",
    "\n",
    "    # Concatenate images side by side\n",
    "    combined = np.concatenate((img1, img2), axis=1)\n",
    "\n",
    "    # Now the points for the second image need to be shifted horizontally by the width of the first image\n",
    "    pts2_shift = np.copy(pts2_nx2)\n",
    "    pts2_shift[:,0] += img1.shape[1]\n",
    "\n",
    "    # Draw all of the lines and points on the image using PIL\n",
    "    combined_img = Image.fromarray(combined)\n",
    "    draw = ImageDraw.Draw(combined_img)\n",
    "\n",
    "    for (x1, y1), (x2, y2) in zip(pts1_nx2, pts2_shift):\n",
    "        draw.line((x1, y1, x2, y2), fill=(255,0,0), width=2)\n",
    "\n",
    "    for x, y in pts1_nx2:\n",
    "        draw.ellipse((x-4, y-4, x+4, y+4), fill=(0,0,255), outline=(0,0,255))\n",
    "\n",
    "    for x, y in pts2_shift:\n",
    "        draw.ellipse((x-4, y-4, x+4, y+4), fill=(0,0,255), outline=(0,0,255))\n",
    "\n",
    "    return combined_img\n",
    "\n",
    "\n",
    "# function [mask, result_img] = backwardWarpImg(src_img, resultToSrc_H, dest_canvas_width_height)\n",
    "\n",
    "def backwardWarpImg(src_img: np.ndarray, destToSrc_H: np.ndarray, canvas_shape: Union[Tuple, List]) -> Tuple[Image.Image, Image.Image]:\n",
    "    '''\n",
    "    Backward warp the source image to the destination canvas based on the\n",
    "    homography given by destToSrc_H. \n",
    "    Arguments:\n",
    "        src_img: the source image.\n",
    "        destToSrc_H: the homography that maps points from the destination\n",
    "            canvas to the source image.\n",
    "        canvas_shape: shape of the destination canvas (height, width).\n",
    "    Returns:\n",
    "        dest_img_array: the warped source image (array format).\n",
    "        dest_mask: a mask indicating sourced pixels. pixels within the\n",
    "            source image are 1, pixels outside are 0.\n",
    "    '''\n",
    "    # For each pixel on the billboard, we need to determine what part of the portrait should be there\n",
    "    # We will accomplish this by applying the inverse Homography matrix to every point in the portrait\n",
    "    # This is not the most efficient implementation but finding a \"vectorized\" method is a bit challenging.\n",
    "\n",
    "    dest_img_array = np.zeros((canvas_shape[0], canvas_shape[1], 3), dtype=float)\n",
    "    dest_mask = np.zeros((canvas_shape[0], canvas_shape[1]), dtype=bool)\n",
    "\n",
    "    for x in range(canvas_shape[1]):\n",
    "        for y in range(canvas_shape[0]):\n",
    "\n",
    "            x_src, y_src, z_tilde = np.dot(destToSrc_H, [x, y, 1]) # Dot product of homogenized point with inverse Homography matrix\n",
    "            x_src = int(x_src/z_tilde) # Dehomogenize x and y points (just using int() to round the pixel location)\n",
    "            y_src = int(y_src/z_tilde)\n",
    "\n",
    "            # Check if the newly mapped pixel should be within the mask\n",
    "            if 0 <= x_src < src_img.shape[1] and 0 <= y_src < src_img.shape[0]:\n",
    "                # If so, add its values (R,G,B) to the destination image and mark the mask with a 1\n",
    "                dest_img_array[y, x, :] = src_img[y_src, x_src, :] \n",
    "                dest_mask[y, x] = 1\n",
    "\n",
    "    return dest_img_array, dest_mask\n",
    "\n",
    "\n",
    "def runRANSAC(src_points: np.ndarray, dest_points: np.ndarray, ransac_n: int, eps: float) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    '''\n",
    "    Run the RANSAC algorithm to find the inliers between the source and\n",
    "    destination points.\n",
    "    Arguments:\n",
    "        src_pt: the coordinates of the source points (nx2 numpy array).\n",
    "        dest_pt: the coordinates of the destination points (nx2 numpy array).\n",
    "        ransac_n: the number of iterations to run RANSAC.\n",
    "        eps: the threshold for considering a point to be an inlier.\n",
    "    Returns:\n",
    "        inliers_id: the indices of the inliers (kx1 numpy array).\n",
    "        H: the homography matrix (3x3 numpy array).\n",
    "    '''\n",
    "\n",
    "    # Solution method: \n",
    "    # For ransac_n iterations:\n",
    "    #   Take a random sample of 4 (src_pt, dest_pt) pairs\n",
    "    #   Compute the homography matrix with that set of pairs\n",
    "    #   Count & store inliers among all of the other points with that set\n",
    "    # Conclude that the 4-pt sequence with the highest number of inliers is the best mapping.\n",
    "\n",
    "    H = None\n",
    "    inliers_id = []\n",
    "\n",
    "    for _ in range(ransac_n):\n",
    "\n",
    "        index = np.random.choice(len(src_points), 4, replace=False)\n",
    "        src_sample = src_points[index]\n",
    "        dest_sample = dest_points[index]\n",
    "    \n",
    "        candidate_H = computeHomography(src_sample, dest_sample) # Compute H using prior method\n",
    "        transformed_src_points = applyHomography(candidate_H, src_points) # Apply homography using candidate H and source points\n",
    "        candidate_distances = np.linalg.norm(dest_points - transformed_src_points, axis=1) # Compute the Euclidean distance using this H\n",
    "        candidate_inliers = np.where(candidate_distances < eps)[0]\n",
    "\n",
    "        if len(candidate_inliers) > len(inliers_id):\n",
    "            print(f\"Just found a new best H with {len(candidate_inliers)} inliers.\")\n",
    "            inliers_id = candidate_inliers\n",
    "            H = candidate_H\n",
    "    \n",
    "    return inliers_id, H\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def blendImagePair(img1: np.ndarray, mask1: np.ndarray, img2: np.ndarray, mask2: np.ndarray, mode: str) -> Image.Image:\n",
    "    '''\n",
    "    Blend the warped images based on the masks.\n",
    "    Arguments:\n",
    "        img1: source image (array).\n",
    "        mask1: source mask (array).\n",
    "        img2: destination image (array).\n",
    "        mask2: destination mask (array).\n",
    "        mode: either 'overlay' or 'blend'\n",
    "    Returns:\n",
    "        out_img: blended image.\n",
    "    '''\n",
    "\n",
    "    print(\"Dimensions of img1:\", img1.shape)\n",
    "    print(\"Dimensions of mask1:\", mask1.shape)\n",
    "    # print(\"Dimensions of img2:\", img2.shape)\n",
    "    # print(\"Dimensions of mask2:\", mask2.shape)\n",
    "\n",
    "    mask1_binary = (mask1 > 0).astype(int)\n",
    "    mask2_binary = (mask2 > 0).astype(int)\n",
    "\n",
    "    result = img1.copy()\n",
    "\n",
    "    if mode not in [\"overlay\", \"blend\"]:\n",
    "        raise ValueError(\"Mode must be 'overlay' or 'blend'\")\n",
    "    \n",
    "    if mode == \"overlay\":\n",
    "        # Overlay processing: copy img2 over img1 wherever mask2 = 1\n",
    "        result[mask2_binary == 1] = img2[mask2_binary == 1]\n",
    "\n",
    "    if mode == \"blend\":\n",
    "        # Blend processing using distance_transform_edt\n",
    "\n",
    "        dt1 = distance_transform_edt(mask1)\n",
    "        dt2 = distance_transform_edt(mask2)\n",
    "        blend_factor = dt2/(dt1 + dt2 + np.finfo(float).eps) # The last term is a very small value to prevent division by 0\n",
    "\n",
    "        # # Expand blend_factor from 1D to 3D to match RGB channels of the images\n",
    "        # if len(img1.shape) == 3:\n",
    "        #     blend_factor = np.repeat(blend_factor[:, :, np.newaxis], 3, axis=2)\n",
    "\n",
    "        # Weighted combination of the input images with blend_factor\n",
    "        result = ((1-blend_factor)*img1 + blend_factor*img2).astype(np.uint8)\n",
    "\n",
    "    out_img = Image.fromarray(result)\n",
    "    return out_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b223240-42ae-40da-a07b-ae05c63ea9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genSIFTMatches(img_s, img_d):\n",
    "    # Convert images to grayscale\n",
    "    gray_s = color.rgb2gray(img_s)\n",
    "    gray_d = color.rgb2gray(img_d)\n",
    "\n",
    "    # Compute SIFT features\n",
    "    sift = feature.SIFT()\n",
    "    sift.detect_and_extract(gray_s)\n",
    "    Fs, Ds = sift.keypoints, sift.descriptors\n",
    "    sift.detect_and_extract(gray_d)\n",
    "    Fd, Dd = sift.keypoints, sift.descriptors\n",
    "\n",
    "    # Match descriptors\n",
    "    matches = feature.match_descriptors(Ds, Dd, cross_check=True)\n",
    "\n",
    "    # Extract the locations of matched keypoints\n",
    "    xs = Fs[matches[:, 0]]\n",
    "    xd = Fd[matches[:, 1]]\n",
    "\n",
    "    return xs, xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7867f845-55cf-4d9d-82f8-f72e506ede9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_center = Image.open('data/mountain_center.png')\n",
    "img_center_array = np.array(img_center)\n",
    "img_left = Image.open('data/mountain_left.png')\n",
    "img_left_array = np.array(img_left)\n",
    "img_right = Image.open('data/mountain_right.png')\n",
    "img_right_array = np.array(img_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08367e85-702b-4dc3-a0bd-8d849222b4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "ad4ab7c1-d451-404c-9d86-094dfbf606b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitchImg(img_d, img_L, img_R):\n",
    "    \"\"\"\n",
    "    Applies a homography to an image and displays the resulting warped image.\n",
    "    \n",
    "    Args:\n",
    "    - img: NumPy array of the source image.\n",
    "    - H: The 3x3 homography matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    sources = [img_L, img_R]\n",
    "    homographies = []\n",
    "    warped_images = []\n",
    "    x_coords = []\n",
    "    x_translations = []\n",
    "    y_coords = []\n",
    "    y_translations = []\n",
    "\n",
    "    intermediates = []\n",
    "\n",
    "    for i, img in enumerate(sources):\n",
    "\n",
    "        height = img_d.shape[1]\n",
    "        width = img_d.shape[0]\n",
    "        \n",
    "        # Compute H\n",
    "        xs, xd = genSIFTMatches(img, img_d)\n",
    "        xs_flip = xs[:,[1,0]]\n",
    "        xd_flip = xd[:,[1,0]]\n",
    "        ransac_n, ransac_eps = 1000, 1\n",
    "        _, H = runRANSAC(xs_flip, xd_flip, ransac_n, ransac_eps)\n",
    "\n",
    "        \n",
    "        # Apply the homography to the source image\n",
    "        height, width = img_d.shape[:2]\n",
    "        corners = np.array([[0, 0, 1], \n",
    "                            [width, 0, 1], \n",
    "                            [width, height, 1], \n",
    "                            [0, height, 1]]).T\n",
    "        \n",
    "    \n",
    "        warped_corners = np.dot(H, corners)\n",
    "        warped_corners = warped_corners[:2] / warped_corners[2]\n",
    "        min_x, min_y = np.min(warped_corners[:2], axis=1)\n",
    "        max_x, max_y = np.max(warped_corners[:2], axis=1)\n",
    "        x_coords.extend(warped_corners[0])\n",
    "        y_coords.extend(warped_corners[1])\n",
    "        \n",
    "        translation = np.array([[1, 0, -min_x], \n",
    "                                [0, 1, -min_y], \n",
    "                                [0, 0, 1]])\n",
    "\n",
    "        x_translations.append(int(min_x))\n",
    "        y_translations.append(int(min_y))\n",
    "        \n",
    "        # Apply the adjusted homography\n",
    "        H_adj = np.dot(translation, H)\n",
    "        homographies.append(H_adj)\n",
    "\n",
    "\n",
    "    # Compute x_range\n",
    "    furthest_negative_x = np.min(x_coords) if np.any(np.array(x_coords) < 0) else 0\n",
    "    largest_positive_x = np.max(x_coords) if np.any(np.array(x_coords) > width) else width\n",
    "    x_range = [furthest_negative_x, largest_positive_x]\n",
    "    \n",
    "    furthest_negative_y = np.min(y_coords) if np.any(np.array(y_coords) < 0) else 0\n",
    "    largest_positive_y = np.max(y_coords) if np.any(np.array(y_coords) > height) else height\n",
    "    y_range = [furthest_negative_y, largest_positive_y]\n",
    "\n",
    "    #print(f\"x_range: {x_range}, y_range: {y_range}\")\n",
    "    \n",
    "    canvas_width = int(abs(x_range[1] - x_range[0]))\n",
    "    canvas_height = int(abs(y_range[1] - y_range[0]))\n",
    "    #print(f\"canvas dimensions: {canvas_height}x{canvas_width} pixels\")\n",
    "\n",
    "    center_canvas = Image.new(\"RGB\", (canvas_width, canvas_height), \"black\")\n",
    "    warped_canvases = [Image.new(\"RGB\", (canvas_width, canvas_height), \"black\") for _ in range(len(sources))]\n",
    "    center_img_placement_x = int((canvas_width - img_d.shape[1]) // 2)\n",
    "    center_img_placement_y = int((canvas_height - img_d.shape[0]) // 2)\n",
    "    \n",
    "    center_canvas.paste(Image.fromarray(img_d), (center_img_placement_x, center_img_placement_y))\n",
    "    #main_canvas.show()\n",
    "\n",
    "    \n",
    "    # Warp the images onto the canvas\n",
    "    for i, img in enumerate(sources):\n",
    "        H = homographies[i]\n",
    "        ### create temporary canvas to store that image ###\n",
    "        warped_arr, _ = backwardWarpImg(img, np.linalg.inv(H), (canvas_height, canvas_width))\n",
    "        warped_img = Image.fromarray(warped_arr.clip(0, 255).astype(np.uint8))\n",
    "\n",
    "        paste_x = center_img_placement_x + x_translations[i]\n",
    "        paste_y = center_img_placement_y + y_translations[i]\n",
    "        \n",
    "        warped_canvases[i].paste(warped_img, (paste_x, paste_y))\n",
    "        #warped_canvases[i].show()\n",
    "\n",
    "\n",
    "    \n",
    "    def to_mask(array):\n",
    "        return (array > 0).astype(np.uint8)*255\n",
    "\n",
    "\n",
    "    warped_arrays = [np.array(img) for img in warped_canvases]\n",
    "    masks = [to_mask(arr) for arr in warped_arrays]\n",
    "    \n",
    "    current_array = np.array(center_canvas)\n",
    "    current_mask = to_mask(current_array)\n",
    "\n",
    "        \n",
    "    # Procedurally blend all of the images\n",
    "    # 2 images -> 1 operation\n",
    "    # 3 images -> 2 operations\n",
    "    # 4 images -> 3 operations\n",
    "    \n",
    "    # first_blend = blendImagePair(center_array, center_mask, warped_arrays[0], masks[0], \"blend\")\n",
    "    # first_blend.show()\n",
    "\n",
    "    \n",
    "    # now, blend the 3rd image into first_blend, and any more images into THAT result, if there are any\n",
    "    for i in range(len(warped_arrays)):  # Start from the second item in warped_arrays\n",
    "        next_image = warped_arrays[i]\n",
    "        next_mask = masks[i]\n",
    "        \n",
    "        # Perform the blend\n",
    "        intermediate = blendImagePair(current_array, current_mask, next_image, next_mask, \"blend\")\n",
    "        #intermediate.show()\n",
    "        \n",
    "        if i == len(warped_arrays):\n",
    "            return intermediate\n",
    "\n",
    "        current_array = np.array(intermediate)  # Update the current result array for the next blending\n",
    "        current_mask = to_mask(current_array)  # Update the mask based on the newly blended image\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "8f29bee1-db2a-43be-ae18-ae5a9e4c7c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just found a new best H with 4 inliers.\n",
      "Just found a new best H with 5 inliers.\n",
      "Just found a new best H with 96 inliers.\n",
      "Just found a new best H with 113 inliers.\n",
      "Just found a new best H with 126 inliers.\n",
      "Just found a new best H with 142 inliers.\n",
      "Just found a new best H with 201 inliers.\n",
      "Just found a new best H with 212 inliers.\n",
      "Just found a new best H with 221 inliers.\n",
      "Just found a new best H with 227 inliers.\n",
      "Just found a new best H with 296 inliers.\n",
      "Just found a new best H with 5 inliers.\n",
      "Just found a new best H with 6 inliers.\n",
      "Just found a new best H with 102 inliers.\n",
      "Just found a new best H with 116 inliers.\n",
      "Just found a new best H with 155 inliers.\n",
      "Just found a new best H with 171 inliers.\n",
      "Dimensions of img1: (975, 2750, 3)\n",
      "Dimensions of mask1: (975, 2750, 3)\n",
      "Dimensions of img1: (975, 2750, 3)\n",
      "Dimensions of mask1: (975, 2750, 3)\n"
     ]
    }
   ],
   "source": [
    "stitchImg(img_center_array, img_left_array, img_right_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "77fc3c4f-d9be-4ac1-8189-a4e418ff12f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_and_display_image(img_d, img_L, img_R):\n",
    "    \"\"\"\n",
    "    Applies a homography to an image and displays the resulting warped image.\n",
    "    \n",
    "    Args:\n",
    "    - img: NumPy array of the source image.\n",
    "    - H: The 3x3 homography matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    sources = [img_L, img_R]\n",
    "    all_corners = []\n",
    "\n",
    "    intermediates = []\n",
    "\n",
    "    for i, img in enumerate(sources):\n",
    "\n",
    "        canvas_width = img_d.shape[1]\n",
    "        canvas_height = img_d.shape[0]\n",
    "        \n",
    "        # Compute H\n",
    "        xs, xd = genSIFTMatches(img, img_d)\n",
    "        xs_flip = xs[:,[1,0]]\n",
    "        xd_flip = xd[:,[1,0]]\n",
    "        ransac_n, ransac_eps = 1000, 1\n",
    "        _, H = runRANSAC(xs_flip, xd_flip, ransac_n, ransac_eps)\n",
    "        \n",
    "        # Apply the homography to the source image\n",
    "        height, width = img_d.shape[:2]\n",
    "        corners = np.array([[0, 0, 1], \n",
    "                            [width, 0, 1], \n",
    "                            [width, height, 1], \n",
    "                            [0, height, 1]]).T\n",
    "    \n",
    "        warped_corners = np.dot(H, corners)\n",
    "        warped_corners = warped_corners[:2] / warped_corners[2]\n",
    "        all_corners.append(warped_corners)\n",
    "        \n",
    "        print(f\"Warped corners: {warped_corners}\")\n",
    "        # Determine location to paste original image onto  \n",
    "        corner1_shift_x = int(corners[0][0] - warped_corners[0][0])\n",
    "        corner1_shift_y = int(corners[1][0] - warped_corners[1][0])\n",
    "    \n",
    "        # Determine the bounds of the new canvas\n",
    "        min_x, min_y = np.min(warped_corners[:2], axis=1)\n",
    "        max_x, max_y = np.max(warped_corners[:2], axis=1)\n",
    "\n",
    "        # Adjust the homography to account for the translation\n",
    "        translation = np.array([[1, 0, -min_x], \n",
    "                                [0, 1, -min_y], \n",
    "                                [0, 0, 1]])\n",
    "\n",
    "        # Apply the adjusted homography\n",
    "        adjusted_H = np.dot(translation, H)\n",
    "        \n",
    "    # Calculate the size of the new canvas (need the canvas dimensions BEFORE warp)\n",
    "    new_width = int(np.ceil(max_x - min_x))\n",
    "    new_height = int(np.ceil(max_y - min_y))\n",
    "\n",
    "    canvas_height = max(new_height, height)\n",
    "    canvas_width = int(canvas_width + new_width)\n",
    "    warped_canvas_shape = (canvas_height, canvas_width)\n",
    "    canvas = Image.new(\"RGB\", (canvas_width, canvas_height), (0, 0, 0))\n",
    "    \n",
    "    warped_arr, warped_mask = backwardWarpImg(img, np.linalg.inv(adjusted_H), warped_canvas_shape)\n",
    "    warped_image = Image.fromarray((warped_arr.clip(0, 255)).astype(np.uint8))\n",
    "        \n",
    "\n",
    "            \n",
    "        warped_image.show()\n",
    "\n",
    "        \n",
    "        # if i==0:\n",
    "        #     print(\"First iteration, also pasting source image\")\n",
    "        #     warped_image.paste(Image.fromarray(img_d), (corner1_shift_x, corner1_shift_y))\n",
    "        #     intermediates.append(warped_image)\n",
    "            \n",
    "        # if i>0:\n",
    "        #     print(f\"subsequent iteration, pasting {intermediates[i-1]}\")\n",
    "        #     intermediates.append(warped_image)\n",
    "        #     #warped_image.paste(intermediates[i-1])\n",
    "\n",
    "        # # Last iteration\n",
    "        # if i==1:\n",
    "            \n",
    "        #     print(f\"Concluding panorama creation with {len(intermediates)} images\")\n",
    "        #     total_intermediate_width = sum(image.width for image in intermediates)\n",
    "        #     total_canvas_width = total_intermediate_width - width\n",
    "        #     total_canvas_height = max(image.height for image in intermediates)\n",
    "            \n",
    "        #     canvas = Image.new(\"RGB\", (total_canvas_width, total_canvas_height), \"black\")\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "79c2b7f6-22a7-43bc-9fae-63ca293e25ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just found a new best H with 4 inliers.\n",
      "Just found a new best H with 49 inliers.\n",
      "Just found a new best H with 201 inliers.\n",
      "Just found a new best H with 203 inliers.\n",
      "Just found a new best H with 212 inliers.\n",
      "Just found a new best H with 227 inliers.\n",
      "Just found a new best H with 243 inliers.\n",
      "Just found a new best H with 251 inliers.\n",
      "Just found a new best H with 281 inliers.\n",
      "Just found a new best H with 290 inliers.\n",
      "Warped corners: [[-858.50470791  514.75703081  523.23065226 -808.15714056]\n",
      " [-138.68316283    5.63181972  676.43756552  826.38363803]]\n",
      "Just found a new best H with 5 inliers.\n",
      "Just found a new best H with 16 inliers.\n",
      "Just found a new best H with 38 inliers.\n",
      "Just found a new best H with 41 inliers.\n",
      "Just found a new best H with 132 inliers.\n",
      "Just found a new best H with 133 inliers.\n",
      "Just found a new best H with 183 inliers.\n",
      "Warped corners: [[ 565.28118284 1877.31867254 1867.67560078  554.59717374]\n",
      " [  19.95730777 -116.73982127  820.64715189  683.02491919]]\n"
     ]
    }
   ],
   "source": [
    "warp_and_display_image(img_center_array, img_left_array, img_right_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2893f0-3399-47c7-b47a-ab302756a1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3354e04-adea-4b8a-8ff7-36e05bd1744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "warped = backwardWarpImg(np.array(img_left), np.linalg.inv(H), img_left_array.shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0d035a-49c1-4245-9edb-f81458c19576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
